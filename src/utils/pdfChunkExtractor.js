/**
 * PDF ì²­í¬ ì¶”ì¶œê¸° (í˜ì´ì§€ ë²”ìœ„ ê¸°ë°˜ ë¶„í• )
 * pdf-libë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ í˜ì´ì§€ ë²”ìœ„ë§Œ ì¶”ì¶œ
 */

import { PDFDocument } from 'pdf-lib';

/**
 * PDFì—ì„œ ì§€ì •ëœ í˜ì´ì§€ ë²”ìœ„ë¥¼ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ PDF ìƒì„±
 * @param {ArrayBuffer} pdfArrayBuffer - ì›ë³¸ PDF ArrayBuffer
 * @param {number} startPage - ì‹œì‘ í˜ì´ì§€ (1ë¶€í„° ì‹œì‘)
 * @param {number} endPage - ì¢…ë£Œ í˜ì´ì§€ (í¬í•¨)
 * @returns {Promise<Object>} { base64, arrayBuffer, pageRange, size, pageCount }
 */
export async function extractPDFChunk(pdfArrayBuffer, startPage, endPage) {
  console.log(`ğŸ“„ PDF ì²­í¬ ì¶”ì¶œ: Page ${startPage}-${endPage}`);
  
  try {
    // ì›ë³¸ PDF ë¡œë“œ
    const pdfDoc = await PDFDocument.load(pdfArrayBuffer);
    const totalPages = pdfDoc.getPageCount();
    
    // í˜ì´ì§€ ë²”ìœ„ ê²€ì¦
    if (startPage < 1 || endPage > totalPages || startPage > endPage) {
      throw new Error(
        `ì˜ëª»ëœ í˜ì´ì§€ ë²”ìœ„: ${startPage}-${endPage} (ì´ ${totalPages} í˜ì´ì§€)`
      );
    }
    
    // ìƒˆ PDF ë¬¸ì„œ ìƒì„±
    const newPdfDoc = await PDFDocument.create();
    
    // ì§€ì •ëœ í˜ì´ì§€ ë²”ìœ„ ë³µì‚¬ (0-based indexë¡œ ë³€í™˜)
    const pageIndices = Array.from(
      { length: endPage - startPage + 1 }, 
      (_, i) => startPage - 1 + i
    );
    
    const copiedPages = await newPdfDoc.copyPages(pdfDoc, pageIndices);
    
    // ë³µì‚¬í•œ í˜ì´ì§€ë“¤ì„ ìƒˆ ë¬¸ì„œì— ì¶”ê°€
    copiedPages.forEach(page => newPdfDoc.addPage(page));
    
    // PDFë¥¼ ArrayBufferë¡œ ì €ì¥
    const pdfBytes = await newPdfDoc.save();
    const chunkArrayBuffer = pdfBytes.buffer;
    
    // Base64 ë³€í™˜
    const base64 = arrayBufferToBase64(chunkArrayBuffer);
    
    const result = {
      base64,
      arrayBuffer: chunkArrayBuffer,
      pageRange: `${startPage}-${endPage}`,
      size: chunkArrayBuffer.byteLength,
      sizeMB: (chunkArrayBuffer.byteLength / 1024 / 1024).toFixed(2),
      pageCount: endPage - startPage + 1
    };
    
    console.log(`  âœ… ì²­í¬ ì¶”ì¶œ ì™„ë£Œ: ${result.pageCount}í˜ì´ì§€, ${result.sizeMB}MB`);
    
    return result;
    
  } catch (error) {
    console.error(`âŒ PDF ì²­í¬ ì¶”ì¶œ ì‹¤íŒ¨:`, error);
    throw new Error(`PDF ì²­í¬ ì¶”ì¶œ ì‹¤íŒ¨: ${error.message}`);
  }
}

/**
 * ì—¬ëŸ¬ ì„¹ì…˜ì„ í•œ ë²ˆì— ì²­í¬ë¡œ ì¶”ì¶œ
 * @param {ArrayBuffer} pdfArrayBuffer - ì›ë³¸ PDF ArrayBuffer
 * @param {Array} sections - ì„¹ì…˜ ëª©ë¡ [{ type, startPage, endPage }]
 * @returns {Promise<Array>} ì²­í¬ ëª©ë¡ [{ ...chunk, type, title }]
 */
export async function extractAllChunks(pdfArrayBuffer, sections) {
  console.log(`ğŸ“¦ ${sections.length}ê°œ ì²­í¬ ì¶”ì¶œ ì‹œì‘...`);
  
  const startTime = Date.now();
  
  // ë³‘ë ¬ ì¶”ì¶œ
  const chunks = await Promise.all(
    sections.map(async (section) => {
      const chunk = await extractPDFChunk(
        pdfArrayBuffer, 
        section.startPage, 
        section.endPage
      );
      
      return {
        ...chunk,
        type: section.type,
        title: section.title
      };
    })
  );
  
  const duration = Date.now() - startTime;
  const totalSize = chunks.reduce((sum, c) => sum + c.size, 0);
  const totalSizeMB = (totalSize / 1024 / 1024).toFixed(2);
  
  console.log(`âœ… ì²­í¬ ì¶”ì¶œ ì™„ë£Œ: ${chunks.length}ê°œ, ì´ ${totalSizeMB}MB (${duration}ms)`);
  
  return chunks;
}

/**
 * ArrayBufferë¥¼ Base64ë¡œ ë³€í™˜
 * @param {ArrayBuffer} buffer - ë³€í™˜í•  ArrayBuffer
 * @returns {string} Base64 ë¬¸ìì—´
 */
function arrayBufferToBase64(buffer) {
  const bytes = new Uint8Array(buffer);
  let binary = '';
  
  // ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
  const chunkSize = 8192;
  for (let i = 0; i < bytes.byteLength; i += chunkSize) {
    const chunk = bytes.subarray(i, Math.min(i + chunkSize, bytes.byteLength));
    binary += String.fromCharCode.apply(null, chunk);
  }
  
  return btoa(binary);
}

/**
 * ì²­í¬ í¬ê¸° ê²€ì¦ (ë„ˆë¬´ í¬ë©´ ê²½ê³ )
 * @param {Array} chunks - ì²­í¬ ëª©ë¡
 * @param {number} maxSizeMB - ìµœëŒ€ í—ˆìš© í¬ê¸° (MB)
 * @returns {Object} { valid, warnings }
 */
export function validateChunkSizes(chunks, maxSizeMB = 3) {
  const warnings = [];
  
  for (const chunk of chunks) {
    const sizeMB = parseFloat(chunk.sizeMB);
    
    if (sizeMB > maxSizeMB) {
      warnings.push({
        chunk: chunk.title,
        pageRange: chunk.pageRange,
        size: chunk.sizeMB,
        message: `ì²­í¬ í¬ê¸°ê°€ ${maxSizeMB}MBë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤ (${chunk.sizeMB}MB)`
      });
    }
  }
  
  if (warnings.length > 0) {
    console.warn(`âš ï¸ ${warnings.length}ê°œ ì²­í¬ê°€ í¬ê¸° ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤:`);
    warnings.forEach(w => console.warn(`  - ${w.message}`));
  }
  
  return {
    valid: warnings.length === 0,
    warnings
  };
}

/**
 * ì²­í¬ í†µê³„ ê³„ì‚°
 * @param {Array} chunks - ì²­í¬ ëª©ë¡
 * @returns {Object} í†µê³„ ì •ë³´
 */
export function calculateChunkStatistics(chunks) {
  const totalPages = chunks.reduce((sum, c) => sum + c.pageCount, 0);
  const totalSize = chunks.reduce((sum, c) => sum + c.size, 0);
  const avgPagesPerChunk = Math.round(totalPages / chunks.length);
  const avgSizePerChunk = (totalSize / chunks.length / 1024 / 1024).toFixed(2);
  
  return {
    totalChunks: chunks.length,
    totalPages,
    totalSizeMB: (totalSize / 1024 / 1024).toFixed(2),
    avgPagesPerChunk,
    avgSizeMB: avgSizePerChunk,
    chunks: chunks.map(c => ({
      title: c.title,
      type: c.type,
      pageRange: c.pageRange,
      pageCount: c.pageCount,
      sizeMB: c.sizeMB
    }))
  };
}
